This directory contains the camera path information of the reference videos of each scene that is used to generate the same camera path for the synthesized videos. The COLMAP framework was used for the pose estimation of the real scenes camera paths. The camera poses of the synthetic scenes were already provided on the *Realistic Synthetic 360ยบ* dataset.

For the *Realistic Synthetic 360ยบ*  scenes, depending on the NeRF based method used implementation, there were two ways of describing the camera path: as a single file (named "camera_path.json") with information about the camera poses and intrinsics for the test time interval images to be synthesized; or with the original "transforms_test.json" file of the *Realistic Synthetic 360ยบ* dataset, as the selected test time interval corresponds to the images sequence contained in the original test set. Most of the implementations enabled the automatic synthesis of that test set.

For the *Tanks and Temples* scenes, depending on the NeRF based method used implementation, there were two ways of describing the camera path: as a single file (named "camera_path.json") with information about the camera poses and intrinsics for the test time interval images to be synthesized; or with the camera path information processed with the camera poses and intrinsics in a separate way. In this case, although the camera intrinsics are the same within the camera poses of each scene, for implementation purposes, two folders were created for each type of information. In each folder, each file corresponds to the respective camera information for each image to be synthesized.